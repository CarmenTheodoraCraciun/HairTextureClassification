{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CarmenTheodoraCraciun/HairTextureClassification/blob/main/DataProcessing_HairTexture.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJDTMxKhlaD1",
        "outputId": "f60e1f93-07d0-4dd5-b885-3eadbc00b0a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opencv-python\n",
            "  Using cached opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (2.0.2)\n",
            "Using cached opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (63.0 MB)\n",
            "Installing collected packages: opencv-python\n",
            "Successfully installed opencv-python-4.11.0.86\n",
            "Collecting tensorflow\n",
            "  Using cached tensorflow-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Collecting astunparse>=1.6.0 (from tensorflow)\n",
            "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
            "  Using cached flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
            "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
            "Collecting libclang>=13.0.0 (from tensorflow)\n",
            "  Using cached libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Collecting tensorboard~=2.19.0 (from tensorflow)\n",
            "  Using cached tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.5.1)\n",
            "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
            "  Using cached tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow)\n",
            "  Using cached wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (14.0.0)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.9)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/lib/python3/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.3.6)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.19.0->tensorflow)\n",
            "  Using cached tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting werkzeug>=1.0.1 (from tensorboard~=2.19.0->tensorflow)\n",
            "  Using cached werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Downloading tensorflow-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (644.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m644.9/644.9 MB\u001b[0m \u001b[31m343.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
            "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
            "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m82.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m98.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m103.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m119.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: libclang, flatbuffers, wheel, werkzeug, tensorflow-io-gcs-filesystem, tensorboard-data-server, google-pasta, tensorboard, astunparse, tensorflow\n",
            "Successfully installed astunparse-1.6.3 flatbuffers-25.2.10 google-pasta-0.2.0 libclang-18.1.1 tensorboard-2.19.0 tensorboard-data-server-0.7.2 tensorflow-2.19.0 tensorflow-io-gcs-filesystem-0.37.1 werkzeug-3.1.3 wheel-0.45.1\n"
          ]
        }
      ],
      "source": [
        "!pip install opencv-python\n",
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eK0jhh-3j70l"
      },
      "source": [
        "# Enviroment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zz7A11DG7GMO",
        "outputId": "28d40dfb-d0dc-4a6c-c971-da18e39fc6b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'HairTextureClassification'...\n",
            "remote: Enumerating objects: 30844, done.\u001b[K\n",
            "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 30844 (delta 6), reused 5 (delta 5), pack-reused 30835 (from 4)\u001b[K\n",
            "Receiving objects: 100% (30844/30844), 824.24 MiB | 33.68 MiB/s, done.\n",
            "Resolving deltas: 100% (52/52), done.\n",
            "Updating files: 100% (16606/16606), done.\n"
          ]
        }
      ],
      "source": [
        "!rm -rf ./HairTextureClassification\n",
        "!git clone https://github.com/CarmenTheodoraCraciun/HairTextureClassification.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "q_EQ9jfWgUcM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import shutil\n",
        "import gc\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import mixed_precision\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lTfZIxl7LND"
      },
      "source": [
        "##Optimizing the training environment\n",
        "\n",
        "* Enabling mixed precision for optimal performance on the GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I60MDMr2iz7O"
      },
      "outputs": [],
      "source": [
        "mixed_precision.set_global_policy('mixed_float16')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_Ny63qZ7Pu-"
      },
      "source": [
        "##Cleaning up the TensorFlow session\n",
        "\n",
        "* to avoid memory issues"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YKfp8cZ7RUz",
        "outputId": "7ce70762-0f19-4779-8b62-d89367b35a29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Garbage collector freed 0 unreachable objects.\n"
          ]
        }
      ],
      "source": [
        "tf.keras.backend.clear_session()\n",
        "collected = gc.collect()\n",
        "print(f\"Garbage collector freed {collected} unreachable objects.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0ztLKXqjcst"
      },
      "source": [
        "# Data processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjiKsJmKzOuj"
      },
      "source": [
        "##Resizes the original images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "PxVvsPQ77fry"
      },
      "outputs": [],
      "source": [
        "def is_image(file_path):\n",
        "    try:\n",
        "        img = cv2.imread(file_path)\n",
        "        return img is not None\n",
        "    except:\n",
        "        return False\n",
        "\n",
        "def resize_image(img, size):\n",
        "    \"\"\"\n",
        "    Resizes an image using bilinear interpolation.\n",
        "\n",
        "    Args:\n",
        "        img: Input image.\n",
        "        size: Desired size of the output image (width, height).\n",
        "\n",
        "    Returns:\n",
        "        Resized image.\n",
        "    \"\"\"\n",
        "    original_height, original_width, _ = img.shape\n",
        "    new_width, new_height = size\n",
        "    resized_img = np.zeros((new_height, new_width, 3), dtype=np.uint8)\n",
        "\n",
        "    for i in range(new_width):\n",
        "        for j in range(new_height):\n",
        "            #i, j = pixel in the resized image\n",
        "            # x, y = pixel in the original image\n",
        "            x = i * (original_width - 1) / (new_width - 1)\n",
        "            y = j * (original_height - 1) / (new_height - 1)\n",
        "\n",
        "            # Neighborhood values\n",
        "            x0 = int(np.floor(x))\n",
        "            x1 = min(x0 + 1, original_width - 1)\n",
        "            y0 = int(np.floor(y))\n",
        "            y1 = min(y0 + 1, original_height - 1)\n",
        "\n",
        "            # Extract the intensity values ​​of neighbors\n",
        "            Ia = img[y0, x0] # stanga sus\n",
        "            Ib = img[y0, x1] # drepata sus\n",
        "            Ic = img[y1, x0] # stanga jos\n",
        "            Id = img[y1, x1] # dreapta jos\n",
        "\n",
        "            # Calculates the weight of each neighboring to the final value\n",
        "            wa = (x1 - x) * (y1 - y)\n",
        "            wb = (x - x0) * (y1 - y)\n",
        "            wc = (x1 - x) * (y - y0)\n",
        "            wd = (x - x0) * (y - y0)\n",
        "\n",
        "            # The final value of the new pixel\n",
        "            pixel = wa * Ia + wb * Ib + wc * Ic + wd * Id\n",
        "            resized_img[j, i] = np.round(pixel).astype(int)\n",
        "\n",
        "    return resized_img\n",
        "\n",
        "def preprocess_images(input_dir, size=(96, 96)):\n",
        "    \"\"\"\n",
        "    Resizes images to the specified size and stores them in memory.\n",
        "\n",
        "    Args:\n",
        "        input_dir: Directory containing the input images.\n",
        "        size: Desired size of the output images (width, height).\n",
        "\n",
        "    Returns:\n",
        "        images: List of processed images as NumPy arrays.\n",
        "        labels: List of corresponding labels.\n",
        "    \"\"\"\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    print(\"Start processing data.\")\n",
        "    for category in os.listdir(input_dir):\n",
        "        category_dir = os.path.join(input_dir, category)\n",
        "        if not os.path.isdir(category_dir):\n",
        "            continue\n",
        "\n",
        "        num_images = 0  # Contor pentru imagini per categorie\n",
        "        for idx, img_name in enumerate(os.listdir(category_dir)):\n",
        "            img_path = os.path.join(category_dir, img_name)\n",
        "\n",
        "            if is_image(img_path):\n",
        "                img = cv2.imread(img_path)\n",
        "                if img is not None:\n",
        "                    img = resize_image(img, size)\n",
        "                    images.append(img)\n",
        "                    labels.append(category)\n",
        "                    num_images += 1\n",
        "                else:\n",
        "                    print(f\"Failed to load image: {img_path}\")\n",
        "            else:\n",
        "                print(f\"Not an image: {img_path}\")\n",
        "\n",
        "        print(f\"Folder {category_dir} has {num_images} images.\")\n",
        "\n",
        "    return np.array(images), np.array(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "NVGQHI1_n6_j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8958cb1c-0407-4be6-c09a-2f9ae066d105"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start processing data.\n",
            "Folder ./HairTextureClassification/originalData/dreadlocks has 467 images.\n",
            "Not an image: ./HairTextureClassification/originalData/curly/rs_1080x1080-200330130638-1080-ariana-grande-curly-hair-instagram-am-033020.gif\n",
            "Folder ./HairTextureClassification/originalData/curly has 2060 images.\n",
            "Folder ./HairTextureClassification/originalData/wavy has 331 images.\n",
            "Folder ./HairTextureClassification/originalData/kinky has 232 images.\n",
            "Folder ./HairTextureClassification/originalData/straight has 530 images.\n"
          ]
        }
      ],
      "source": [
        "processed_images, processed_labels = preprocess_images('./HairTextureClassification/originalData', size=(96, 96))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3ukVocGk62U"
      },
      "source": [
        "## Oversampling for rare classes and Normalization\n",
        "\n",
        "* Classes like straight, curly, dreadlocks have over more images.\n",
        "* normalization: to contain only 0 and 1 values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "krU20qP4lAZv"
      },
      "outputs": [],
      "source": [
        "def augumentation_images(images, labels, max_images_per_class=2000, size=(96, 96)):\n",
        "    class_counts_dict = Counter(labels)\n",
        "    class_counts = list(class_counts_dict.values())\n",
        "    class_names = list(class_counts_dict.keys())\n",
        "\n",
        "    augment_multiplier = {cls: max(1, max_images_per_class // count) for cls, count in zip(class_names, class_counts)}\n",
        "\n",
        "    print(\"Augment multipliers:\", augment_multiplier)\n",
        "\n",
        "    datagen = ImageDataGenerator(\n",
        "        rotation_range=20,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest',\n",
        "    )\n",
        "\n",
        "    augmented_images = []\n",
        "    augmented_labels = []\n",
        "\n",
        "    for img, label in zip(images, labels):\n",
        "        img = img[np.newaxis, ...]  # Expand dimensions for datagen flow\n",
        "        gen = datagen.flow(img, batch_size=1)\n",
        "\n",
        "        num_augmentations = augment_multiplier[label]\n",
        "\n",
        "        for _ in range(num_augmentations):\n",
        "            aug_img = next(gen)[0]\n",
        "            aug_img = cv2.resize(aug_img, size, interpolation=cv2.INTER_LINEAR)\n",
        "            augmented_images.append(aug_img)\n",
        "            augmented_labels.append(label)\n",
        "\n",
        "    images_augmented = np.array(augmented_images)\n",
        "    labels_augmented = np.array(augmented_labels)\n",
        "\n",
        "    print(\"The new class distribution:\", Counter(labels_augmented))\n",
        "    print(f\"Enlarged image dimensions: {images_augmented.shape}\")\n",
        "    print(f\"Enlarged label sizes: {labels_augmented.shape}\")\n",
        "\n",
        "    return images_augmented, labels_augmented\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "jaTZI90V7Y1-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8711ed41-7da3-47f9-bd6d-37ef919293ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Augment multipliers: {np.str_('dreadlocks'): 4, np.str_('curly'): 1, np.str_('wavy'): 6, np.str_('kinky'): 8, np.str_('straight'): 3}\n",
            "The new class distribution: Counter({np.str_('curly'): 2060, np.str_('wavy'): 1986, np.str_('dreadlocks'): 1868, np.str_('kinky'): 1856, np.str_('straight'): 1590})\n",
            "Enlarged image dimensions: (9360, 96, 96, 3)\n",
            "Enlarged label sizes: (9360,)\n"
          ]
        }
      ],
      "source": [
        "images_augmented, labels_augmented = augumentation_images(processed_images, processed_labels, 2000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "GZIgAZVm_a9w"
      },
      "outputs": [],
      "source": [
        "def save_images_to_folders(images, labels, images_augmented, labels_augmented, output_dir=\"HairTextureClassification/processedData\"):\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    class_counts = {}\n",
        "\n",
        "    for img, label in zip(images, labels):\n",
        "        assert img.shape[:2] == (96, 96), f\"Error: Original image {label} is not 96x96!\"\n",
        "        class_dir = os.path.join(output_dir, label)\n",
        "        if not os.path.exists(class_dir):\n",
        "            os.makedirs(class_dir)\n",
        "\n",
        "        class_counts[label] = class_counts.get(label, 0) + 1\n",
        "        file_name = f\"{label}_{class_counts[label]}.png\"\n",
        "\n",
        "        cv2.imwrite(os.path.join(class_dir, file_name), img.astype(np.uint8))\n",
        "\n",
        "    for img, label in zip(images_augmented, labels_augmented):\n",
        "        assert img.shape[:2] == (96, 96), f\"Error: Augmented image {label} is not 96x96!\"\n",
        "        class_dir = os.path.join(output_dir, label)\n",
        "        if not os.path.exists(class_dir):\n",
        "            os.makedirs(class_dir)\n",
        "\n",
        "        class_counts[label] += 1\n",
        "        file_name = f\"{label}_{class_counts[label]}.png\"\n",
        "\n",
        "        cv2.imwrite(os.path.join(class_dir, file_name), img.astype(np.uint8))\n",
        "\n",
        "    print(f\"Saved original and augmented images in {output_dir}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "CsLEbVDPCMSF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "010b1b65-f951-45c2-abd0-bbe75261b325"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved original and augmented images in HairTextureClassification/processedData\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_adad5e69-367e-49f6-8b47-7d115a6822c0\", \"processedData.zip\", 222955390)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "save_images_to_folders(processed_images, processed_labels, images_augmented, labels_augmented)\n",
        "shutil.\n",
        "\n",
        "make_archive(\"processedData\", \"zip\", \"HairTextureClassification/processedData\")\n",
        "files.download(\"processedData.zip\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [
        "q0ztLKXqjcst",
        "ir75CD9-7vJ3",
        "1BXGX1tpHWxV",
        "3LlzM5B6lzSw",
        "BXZM9Ts2ZPFs",
        "SPjjmWRcMjh0"
      ],
      "gpuType": "V28",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}